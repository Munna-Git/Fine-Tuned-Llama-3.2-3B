{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KfyL2EBhZHH",
        "outputId": "d85700b8-76d6-4e36-a25a-e939d99bd996"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "ğŸ“¦ ACORD Dataset Conversion - Google Drive Format\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import random\n",
        "from collections import defaultdict, Counter\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"ğŸ“¦ ACORD Dataset Conversion - Google Drive Format\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfPA8CFcp-ou"
      },
      "outputs": [],
      "source": [
        "# Define paths - UPDATE THESE based on where you upload files\n",
        "CORPUS_PATH = \"corpus.jsonl\"\n",
        "QUERIES_PATH = \"queries.jsonl\"\n",
        "QRELS_PATH = \"qrels\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKhK9H9qmAA",
        "outputId": "78cd5b5e-8e9b-4aee-80b3-66b9462dd15e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“‚ Loading ACORD files...\n",
            "Loading corpus from: corpus.jsonl\n",
            "âœ… Loaded 3931 clauses\n",
            "Loading queries from: queries.jsonl\n",
            "âœ… Loaded 114 queries\n",
            "\n",
            "ğŸ“‹ Example Corpus Entry:\n",
            "   ID: a5a68dbd19\n",
            "   Text: In no event may either party sell, disclose, transfer, rent, or license Payment-Eligible User Data to the other party's Named Competitors as listed in EXHIBIT E. Furthermore, Excite@Home may not sell,...\n",
            "   Metadata: {}\n",
            "\n",
            "ğŸ“‹ Example Query:\n",
            "   ID: New York Governing Law\n",
            "   Text: New York Governing Law\n",
            "   Metadata: {'category': 'Governing Law', 'parent_query_id': '', 'type': 'cuad1', 'split': 'train'}\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nğŸ“‚ Loading ACORD files...\")\n",
        "\n",
        "# Load corpus (contract clauses)\n",
        "print(f\"Loading corpus from: {CORPUS_PATH}\")\n",
        "corpus_dict = {}\n",
        "with open(CORPUS_PATH, 'r') as f:\n",
        "    for line in f:\n",
        "        item = json.loads(line)\n",
        "        corpus_dict[item['_id']] = item\n",
        "print(f\"âœ… Loaded {len(corpus_dict)} clauses\")\n",
        "\n",
        "# Load queries (clause type descriptions)\n",
        "print(f\"Loading queries from: {QUERIES_PATH}\")\n",
        "queries_dict = {}\n",
        "with open(QUERIES_PATH, 'r') as f:\n",
        "    for line in f:\n",
        "        item = json.loads(line)\n",
        "        queries_dict[item['_id']] = item\n",
        "print(f\"âœ… Loaded {len(queries_dict)} queries\")\n",
        "\n",
        "# Show examples\n",
        "print(f\"\\nğŸ“‹ Example Corpus Entry:\")\n",
        "if corpus_dict:\n",
        "    sample_corpus_id = list(corpus_dict.keys())[0]\n",
        "    sample_corpus = corpus_dict[sample_corpus_id]\n",
        "    print(f\"   ID: {sample_corpus['_id']}\")\n",
        "    print(f\"   Text: {sample_corpus['text'][:200]}...\")\n",
        "    print(f\"   Metadata: {sample_corpus.get('metadata', {})}\")\n",
        "else:\n",
        "    print(\"   Corpus is empty.\")\n",
        "\n",
        "print(f\"\\nğŸ“‹ Example Query:\")\n",
        "if queries_dict:\n",
        "    sample_query_id = list(queries_dict.keys())[0]\n",
        "    sample_query = queries_dict[sample_query_id]\n",
        "    print(f\"   ID: {sample_query['_id']}\")\n",
        "    print(f\"   Text: {sample_query['text']}\")\n",
        "    print(f\"   Metadata: {sample_query.get('metadata', {})}\")\n",
        "else:\n",
        "    print(\"   Queries are empty.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EKbj2VUqx3q",
        "outputId": "d7c18102-6f97-48ff-e679-0b96046f8927"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“Š Loading qrels (relevance judgments)...\n",
            "âœ… Loaded 58529 qrels for train\n",
            "âœ… Loaded 61988 qrels for test\n",
            "âš ï¸  dev.tsv not found, skipping...\n",
            "\n",
            "ğŸ“ˆ Qrels Statistics:\n",
            "   train: 58529 pairs\n",
            "      Score distribution: Counter({0: 56973, 1: 1036, 3: 287, 2: 159, 4: 74})\n",
            "   test: 61988 pairs\n",
            "      Score distribution: Counter({0: 60231, 1: 1137, 3: 348, 2: 219, 4: 53})\n"
          ]
        }
      ],
      "source": [
        " #CELL 2: Load Qrels (Relevance Judgments)\n",
        "# ============================================================================\n",
        "\n",
        "def load_qrels(qrels_folder):\n",
        "    \"\"\"\n",
        "    Load qrels files (TSV format: query-id corpus-id score)\n",
        "    Returns dict mapping splits to list of (query_id, corpus_id, score) tuples\n",
        "    \"\"\"\n",
        "    qrels_data = {}\n",
        "\n",
        "    # Look for train, test, validation TSV files\n",
        "    qrels_files = {\n",
        "        'train': 'train.tsv',\n",
        "        'test': 'test.tsv',\n",
        "        'validation': 'dev.tsv'  # Sometimes called dev.tsv\n",
        "    }\n",
        "\n",
        "    for split, filename in qrels_files.items():\n",
        "        filepath = os.path.join(qrels_folder, filename)\n",
        "        if not os.path.exists(filepath):\n",
        "            print(f\"âš ï¸  {filename} not found, skipping...\")\n",
        "            continue\n",
        "\n",
        "        qrels_data[split] = []\n",
        "        with open(filepath, 'r') as f:\n",
        "            # Skip the header row\n",
        "            next(f)\n",
        "            for line in f:\n",
        "                parts = line.strip().split('\\t')\n",
        "                if len(parts) >= 3:\n",
        "                    query_id = parts[0]\n",
        "                    corpus_id = parts[1]\n",
        "                    score = int(parts[2])\n",
        "                    qrels_data[split].append((query_id, corpus_id, score))\n",
        "\n",
        "        print(f\"âœ… Loaded {len(qrels_data[split])} qrels for {split}\")\n",
        "\n",
        "    return qrels_data\n",
        "\n",
        "print(f\"\\nğŸ“Š Loading qrels (relevance judgments)...\")\n",
        "qrels = load_qrels(QRELS_PATH)\n",
        "\n",
        "# Show statistics\n",
        "print(f\"\\nğŸ“ˆ Qrels Statistics:\")\n",
        "for split, data in qrels.items():\n",
        "    scores = [score for _, _, score in data]\n",
        "    print(f\"   {split}: {len(data)} pairs\")\n",
        "    print(f\"      Score distribution: {Counter(scores)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQFuGG0x2omD",
        "outputId": "4b1b5af8-9f7c-4b46-ac79-4b64cd036eff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ” Exploring ACORD Structure...\n",
            "================================================================================\n",
            "\n",
            "ğŸ“‹ Sample Query:\n",
            "{\n",
            "  \"_id\": \"New York Governing Law\",\n",
            "  \"text\": \"New York Governing Law\",\n",
            "  \"metadata\": {\n",
            "    \"category\": \"Governing Law\",\n",
            "    \"parent_query_id\": \"\",\n",
            "    \"type\": \"cuad1\",\n",
            "    \"split\": \"train\"\n",
            "  }\n",
            "}\n",
            "\n",
            "ğŸ“‹ Sample Corpus Entry:\n",
            "{\n",
            "  \"_id\": \"a5a68dbd19\",\n",
            "  \"text\": \"In no event may either party sell, disclose, transfer, rent, or license Payment-Eligible User Data to the other party's Named Competitors as listed in EXHIBIT E. Furthermore, Excite@Home may not sell, disclose, transfer, rent, or license Shopping Category Data or Superset Data to Data Restricted Named Companies as specified in EXHIBIT I. Not more than once per quarter, Application Provider may update the list of Application Provider Data Restricted Named Compa\n",
            "\n",
            "ğŸ“Š ACORD Statistics:\n",
            "   Queries: 114 expert-written\n",
            "   Clauses: 3931 from contracts\n",
            "   Query-Clause Pairs: 120517\n",
            "   Ratings: 0-4 stars (by lawyers)\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 2: Explore ACORD Format\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nğŸ” Exploring ACORD Structure...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ACORD uses BEIR format with 3 components:\n",
        "# 1. Queries (questions asking for specific clause types)\n",
        "# 2. Corpus (actual clause texts from contracts)\n",
        "# 3. Qrels (relevance scores: 0-4 stars, where 0=irrelevant, 4=perfect)\n",
        "\n",
        "print(f\"\\nğŸ“‹ Sample Query:\")\n",
        "if queries_dict:\n",
        "    sample_query = list(queries_dict.values())[0]\n",
        "    print(json.dumps(sample_query, indent=2)[:500])\n",
        "else:\n",
        "    print(\"   Queries dictionary is empty.\")\n",
        "\n",
        "\n",
        "print(f\"\\nğŸ“‹ Sample Corpus Entry:\")\n",
        "if corpus_dict:\n",
        "    sample_corpus = list(corpus_dict.values())[0]\n",
        "    print(json.dumps(sample_corpus, indent=2)[:500])\n",
        "else:\n",
        "    print(\"   Corpus dictionary is empty.\")\n",
        "\n",
        "\n",
        "print(f\"\\nğŸ“Š ACORD Statistics:\")\n",
        "print(f\"   Queries: {len(queries_dict)} expert-written\")\n",
        "print(f\"   Clauses: {len(corpus_dict)} from contracts\")\n",
        "total_pairs = sum(len(qrels[split]) for split in qrels) # Summing up pairs from all splits in qrels\n",
        "print(f\"   Query-Clause Pairs: {total_pairs}\")\n",
        "print(f\"   Ratings: 0-4 stars (by lawyers)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIMYty3I3FUc",
        "outputId": "e9d01b87-6fc2-4375-8c7e-8ef894b4954b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ”„ Converting ACORD to instruction format...\n",
            "================================================================================\n",
            "âœ… Conversion complete!\n",
            "   train: 347 samples\n",
            "   test: 391 samples\n",
            "\n",
            "ğŸ“ Example Training Sample:\n",
            "   Instruction: Extract the exact Limitation of Liability clause that matches this requirement\n",
            "   Input (first 200 chars): Requirement: Cap on liability without carveouts\n",
            "\n",
            "Contract Text: 15. LIMITATIONS OF LIABILITY\n",
            "MORPHO agrees that XIMAGE's total liability to MORPHO for any damages suffered in connection with, or arisi...\n",
            "   Output (first 200 chars): 15. LIMITATIONS OF LIABILITY\n",
            "MORPHO agrees that XIMAGE's total liability to MORPHO for any damages suffered in connection with, or arising out of, this Agreement or MORPHO's use of any documentation, ...\n",
            "   Clause Type: Limitation of Liability\n",
            "   Relevance: 3/4 stars\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 3: Convert ACORD to Training Format\n",
        "# ============================================================================\n",
        "\n",
        "import json\n",
        "from collections import defaultdict\n",
        "\n",
        "print(\"\\nğŸ”„ Converting ACORD to instruction format...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def convert_acord_to_instruction_format(qrels_data, queries_dict, corpus_dict, min_relevance=3):\n",
        "    \"\"\"\n",
        "    Convert ACORD BEIR format to instruction format for fine-tuning.\n",
        "\n",
        "    Args:\n",
        "        qrels_data: Dict of split -> list of (query_id, corpus_id, score) tuples\n",
        "        queries_dict: Dict of query_id -> query object\n",
        "        corpus_dict: Dict of corpus_id -> corpus object\n",
        "        min_relevance: Minimum relevance score (0-4). Default 3 = 4-5 star clauses.\n",
        "\n",
        "    Returns:\n",
        "        Dict of split -> list of training samples in instruction format\n",
        "    \"\"\"\n",
        "\n",
        "    converted_data = {}\n",
        "\n",
        "    for split, qrel_list in qrels_data.items():\n",
        "        samples = []\n",
        "\n",
        "        for query_id, corpus_id, score in qrel_list:\n",
        "            # Filter by minimum score (3-4 stars = good/excellent)\n",
        "            if score < min_relevance:\n",
        "                continue\n",
        "\n",
        "            # Get query and corpus objects\n",
        "            query = queries_dict.get(query_id)\n",
        "            corpus_item = corpus_dict.get(corpus_id)\n",
        "\n",
        "            if not query or not corpus_item:\n",
        "                continue\n",
        "\n",
        "            # Extract data\n",
        "            query_text = query['text']\n",
        "            clause_text = corpus_item['text']\n",
        "            category = query.get('metadata', {}).get('category', 'General')\n",
        "\n",
        "            # Create instruction format sample\n",
        "            sample = {\n",
        "                'instruction': f'Extract the exact {category} clause that matches this requirement',\n",
        "                'input': f\"Requirement: {query_text}\\n\\nContract Text: {clause_text}\",\n",
        "                'output': clause_text,\n",
        "                'clause_type': category,\n",
        "                'relevance_score': score,\n",
        "                'metadata': {\n",
        "                    'query': query_text,\n",
        "                    'split': split\n",
        "                }\n",
        "            }\n",
        "\n",
        "            samples.append(sample)\n",
        "\n",
        "        converted_data[split] = samples\n",
        "\n",
        "    return converted_data\n",
        "\n",
        "# Convert data with min_relevance=3 (only 3-4 star clauses)\n",
        "acord_data = convert_acord_to_instruction_format(qrels, queries_dict, corpus_dict, min_relevance=3)\n",
        "\n",
        "print(f\"âœ… Conversion complete!\")\n",
        "for split, samples in acord_data.items():\n",
        "    print(f\"   {split}: {len(samples)} samples\")\n",
        "\n",
        "# Show example\n",
        "if 'train' in acord_data and len(acord_data['train']) > 0:\n",
        "    print(f\"\\nğŸ“ Example Training Sample:\")\n",
        "    example = acord_data['train'][0]\n",
        "    print(f\"   Instruction: {example['instruction']}\")\n",
        "    print(f\"   Input (first 200 chars): {example['input'][:200]}...\")\n",
        "    print(f\"   Output (first 200 chars): {example['output'][:200]}...\")\n",
        "    print(f\"   Clause Type: {example['clause_type']}\")\n",
        "    print(f\"   Relevance: {example['relevance_score']}/4 stars\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-lZU0kZ3ZyE",
        "outputId": "c9c503b1-68fe-4299-ccff-0527445447a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ”„ Applying data augmentation...\n",
            "================================================================================\n",
            "Current dataset size: 1041 samples\n",
            "âš ï¸ Dataset is small - applying 3x augmentation\n",
            "âœ… Train: 884 â†’ 2652 samples\n",
            "âœ… Validation: 157 â†’ 471 samples\n",
            "âœ… Test: 391 samples (no augmentation)\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "print(\"\\nğŸ”„ Applying data augmentation...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def augment_training_data(data, augmentation_factor=2):\n",
        "    \"\"\"Augment training data by creating variations.\"\"\"\n",
        "\n",
        "    augmented = []\n",
        "\n",
        "    instruction_templates = [\n",
        "        'Extract the exact {clause_type} clause that matches this requirement',\n",
        "        'Copy the {clause_type} clause from this contract that satisfies the following',\n",
        "        'Find and extract the {clause_type} clause based on this description',\n",
        "        'Locate the {clause_type} clause in the contract matching',\n",
        "        'Identify and extract the relevant {clause_type} clause for',\n",
        "    ]\n",
        "\n",
        "    for sample in data:\n",
        "        augmented.append(sample)  # Original\n",
        "\n",
        "        # Create variations\n",
        "        for i in range(augmentation_factor - 1):\n",
        "            template = random.choice(instruction_templates)\n",
        "            aug_sample = sample.copy()\n",
        "            aug_sample['instruction'] = template.format(\n",
        "                clause_type=sample['clause_type']\n",
        "            )\n",
        "            augmented.append(aug_sample)\n",
        "\n",
        "    return augmented\n",
        "\n",
        "# Check combined train+val size\n",
        "all_data_size = 0\n",
        "if 'train' in acord_data:\n",
        "    all_data_size += len(acord_data['train'])\n",
        "if 'validation' in acord_data:\n",
        "    all_data_size += len(acord_data['validation'])\n",
        "\n",
        "print(f\"Current dataset size: {all_data_size} samples\")\n",
        "\n",
        "# FORCE 3x augmentation since dataset is small\n",
        "augmentation_factor = 3\n",
        "print(f\"âš ï¸ Dataset is small - applying {augmentation_factor}x augmentation\")\n",
        "\n",
        "if 'train' in acord_data:\n",
        "    original_size = len(acord_data['train'])\n",
        "    acord_data['train'] = augment_training_data(acord_data['train'], augmentation_factor)\n",
        "    print(f\"âœ… Train: {original_size} â†’ {len(acord_data['train'])} samples\")\n",
        "\n",
        "if 'validation' in acord_data:\n",
        "    original_size = len(acord_data['validation'])\n",
        "    acord_data['validation'] = augment_training_data(acord_data['validation'], augmentation_factor)\n",
        "    print(f\"âœ… Validation: {original_size} â†’ {len(acord_data['validation'])} samples\")\n",
        "\n",
        "# Test is NOT augmented\n",
        "print(f\"âœ… Test: {len(acord_data['test'])} samples (no augmentation)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qML9NDb3hPX",
        "outputId": "f584f577-2232-4d24-b5f1-317de6451e79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“Š Creating data splits...\n",
            "================================================================================\n",
            "âœ… Data splits:\n",
            "   Train: 2652 samples\n",
            "   Validation: 471 samples\n",
            "   Test: 391 samples\n",
            "\n",
            "ğŸ“‹ Clause type distribution in training set:\n",
            "   Limitation of Liability: 1644\n",
            "   Indemnification: 513\n",
            "   Restrictive Covenants: 189\n",
            "   Term: 123\n",
            "   Governing Law: 90\n",
            "   Affirmative Covenants: 48\n",
            "   IP Ownership/License: 45\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 5: Create Train/Val/Test Splits\n",
        "# ============================================================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "\n",
        "print(\"\\nğŸ“Š Creating data splits...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# If validation split doesn't exist, create it from train\n",
        "if 'validation' not in acord_data and 'train' in acord_data:\n",
        "    print(\"âš ï¸ No validation split found, creating from train data...\")\n",
        "    train_data = acord_data['train']\n",
        "    random.seed(42)\n",
        "    random.shuffle(train_data)\n",
        "\n",
        "    # Split: 85% train, 15% val\n",
        "    train_split, val_split = train_test_split(train_data, test_size=0.15, random_state=42)\n",
        "    acord_data['train'] = train_split\n",
        "    acord_data['validation'] = val_split\n",
        "    print(f\"âœ… Created validation split from train data\")\n",
        "\n",
        "# Use existing splits\n",
        "train_split = acord_data.get('train', [])\n",
        "val_split = acord_data.get('validation', [])\n",
        "test_split = acord_data.get('test', [])\n",
        "\n",
        "print(f\"âœ… Data splits:\")\n",
        "print(f\"   Train: {len(train_split)} samples\")\n",
        "print(f\"   Validation: {len(val_split)} samples\")\n",
        "print(f\"   Test: {len(test_split)} samples\")\n",
        "\n",
        "# Verify clause type distribution\n",
        "train_types = Counter(s['clause_type'] for s in train_split)\n",
        "print(f\"\\nğŸ“‹ Clause type distribution in training set:\")\n",
        "for clause_type, count in train_types.most_common():\n",
        "    print(f\"   {clause_type}: {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wz8anns4Hck",
        "outputId": "5f0f1fb8-cf84-4b1a-c7f0-dbe0cedc6181"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ’¾ Saving converted ACORD data...\n",
            "================================================================================\n",
            "âœ… Saved train.json - 2652 samples (9.25 MB)\n",
            "âœ… Saved val.json - 471 samples (1.68 MB)\n",
            "âœ… Saved test.json - 391 samples (1.42 MB)\n",
            "\n",
            "âœ… All data saved to: /kaggle/working/acord_data\n",
            "   Files: train.json, val.json, test.json, metadata.json\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 6: Save Converted Data\n",
        "# ============================================================================\n",
        "\n",
        "import json\n",
        "import os\n",
        "\n",
        "print(\"\\nğŸ’¾ Saving converted ACORD data...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Create output directory\n",
        "output_dir = \"/kaggle/working/acord_data\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Save splits\n",
        "splits = {\n",
        "    'train': train_split,\n",
        "    'val': val_split,\n",
        "    'test': test_split\n",
        "}\n",
        "\n",
        "for split_name, split_data in splits.items():\n",
        "    output_path = f\"{output_dir}/{split_name}.json\"\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(split_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    file_size_mb = os.path.getsize(output_path) / 1024 / 1024\n",
        "    print(f\"âœ… Saved {split_name}.json - {len(split_data)} samples ({file_size_mb:.2f} MB)\")\n",
        "\n",
        "# Save metadata\n",
        "metadata = {\n",
        "    'dataset': 'ACORD (Atticus Clause Retrieval Dataset)',\n",
        "    'source': 'theatticusproject/acord (local files)',\n",
        "    'conversion_date': '2025-10-30',\n",
        "    'min_relevance': 3,\n",
        "    'augmentation_factor': augmentation_factor,\n",
        "    'splits': {\n",
        "        'train': len(train_split),\n",
        "        'validation': len(val_split),\n",
        "        'test': len(test_split)\n",
        "    },\n",
        "    'clause_types': dict(train_types)\n",
        "}\n",
        "\n",
        "with open(f\"{output_dir}/metadata.json\", 'w') as f:\n",
        "    json.dump(metadata, f, indent=2)\n",
        "\n",
        "print(f\"\\nâœ… All data saved to: {output_dir}\")\n",
        "print(f\"   Files: train.json, val.json, test.json, metadata.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEe0oXDD4Sun",
        "outputId": "25d21e74-7794-4dff-ef3e-5d5d8c078bdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ” Validating data quality...\n",
            "================================================================================\n",
            "âœ… Train data quality: EXCELLENT\n",
            "\n",
            "ğŸ“Š Train Statistics:\n",
            "   Average input length: 1701 characters\n",
            "   Average output length: 1621 characters\n",
            "   Input/Output ratio: 1.05x\n",
            "âœ… Validation data quality: EXCELLENT\n",
            "\n",
            "ğŸ“Š Validation Statistics:\n",
            "   Average input length: 1740 characters\n",
            "   Average output length: 1659 characters\n",
            "   Input/Output ratio: 1.05x\n",
            "âœ… Test data quality: EXCELLENT\n",
            "\n",
            "ğŸ“Š Test Statistics:\n",
            "   Average input length: 1773 characters\n",
            "   Average output length: 1701 characters\n",
            "   Input/Output ratio: 1.04x\n",
            "\n",
            "ğŸ‰ ALL DATA VALIDATED - READY FOR TRAINING!\n",
            "\n",
            "ğŸ“ Next Steps:\n",
            "   1. Use these paths in your training code:\n",
            "      TRAIN_PATH = '/kaggle/working/acord_data/train.json'\n",
            "      VAL_PATH = '/kaggle/working/acord_data/val.json'\n",
            "   2. Rest of your training code stays THE SAME!\n",
            "   3. Expected results: 60-80% similarity (vs CUAD's 24%)\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 7: Data Quality Validation\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nğŸ” Validating data quality...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def validate_training_data(data, split_name='train'):\n",
        "    \"\"\"Validate that ACORD data is correctly formatted and high quality.\"\"\"\n",
        "\n",
        "    issues = []\n",
        "\n",
        "    for i, sample in enumerate(data[:100]):  # Check first 100\n",
        "        # Check required fields\n",
        "        if not sample.get('instruction'):\n",
        "            issues.append(f\"Sample {i}: Missing instruction\")\n",
        "        if not sample.get('input'):\n",
        "            issues.append(f\"Sample {i}: Missing input\")\n",
        "        if not sample.get('output'):\n",
        "            issues.append(f\"Sample {i}: Missing output\")\n",
        "\n",
        "        # Check that output is substring of input (for extraction task)\n",
        "        if sample.get('output') and sample.get('input'):\n",
        "            # For ACORD, output should be in input (same clause)\n",
        "            # This is KEY difference from CUAD where they didn't match!\n",
        "            if sample['output'] not in sample['input']:\n",
        "                issues.append(f\"Sample {i}: Output not found in input\")\n",
        "\n",
        "        # Check length\n",
        "        if len(sample.get('output', '')) < 20:\n",
        "            issues.append(f\"Sample {i}: Output too short ({len(sample['output'])} chars)\")\n",
        "\n",
        "    if issues:\n",
        "        print(f\"âš ï¸ Found {len(issues)} potential issues in {split_name}:\")\n",
        "        for issue in issues[:10]:  # Show first 10\n",
        "            print(f\"   {issue}\")\n",
        "    else:\n",
        "        print(f\"âœ… {split_name} data quality: EXCELLENT\")\n",
        "\n",
        "    # Statistics\n",
        "    avg_input_len = sum(len(s['input']) for s in data) / len(data)\n",
        "    avg_output_len = sum(len(s['output']) for s in data) / len(data)\n",
        "\n",
        "    print(f\"\\nğŸ“Š {split_name} Statistics:\")\n",
        "    print(f\"   Average input length: {avg_input_len:.0f} characters\")\n",
        "    print(f\"   Average output length: {avg_output_len:.0f} characters\")\n",
        "    print(f\"   Input/Output ratio: {avg_input_len/avg_output_len:.2f}x\")\n",
        "\n",
        "    return len(issues) == 0\n",
        "\n",
        "# Validate all splits\n",
        "train_valid = validate_training_data(train_split, 'Train')\n",
        "val_valid = validate_training_data(val_split, 'Validation')\n",
        "test_valid = validate_training_data(test_split, 'Test')\n",
        "\n",
        "if train_valid and val_valid and test_valid:\n",
        "    print(f\"\\nğŸ‰ ALL DATA VALIDATED - READY FOR TRAINING!\")\n",
        "    print(f\"\\nğŸ“ Next Steps:\")\n",
        "    print(f\"   1. Use these paths in your training code:\")\n",
        "    print(f\"      TRAIN_PATH = '/kaggle/working/acord_data/train.json'\")\n",
        "    print(f\"      VAL_PATH = '/kaggle/working/acord_data/val.json'\")\n",
        "    print(f\"   2. Rest of your training code stays THE SAME!\")\n",
        "    print(f\"   3. Expected results: 60-80% similarity (vs CUAD's 24%)\")\n",
        "else:\n",
        "    print(f\"\\nâš ï¸ Please review and fix issues before training\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkQV4bJKu25u"
      },
      "source": [
        "# From here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TQZw6OT3gXM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8BV2UrSuwbf"
      },
      "outputs": [],
      "source": [
        "# Install datasets library\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', 'datasets'])\n",
        "\n",
        "print(\"ğŸ“¥ Downloading ACORD dataset...\")\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Download ACORD\n",
        "acord_data = load_dataset(\"theatticusproject/acord\")\n",
        "\n",
        "print(f\"âœ… ACORD loaded!\")\n",
        "print(f\"   Train split: {len(acord_data['train'])} samples\")\n",
        "print(f\"   Test split: {len(acord_data['test'])} samples\")\n",
        "print(f\"   Validation split: {len(acord_data['validation'])} samples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MV8GCsItupXS"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "print(\"ğŸ” Exploring ACORD Structure...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ACORD uses BEIR format with 3 components:\n",
        "# 1. Queries (questions asking for specific clause types)\n",
        "# 2. Corpus (actual clause texts from contracts)\n",
        "# 3. Qrels (relevance scores: 0-4 stars, where 0=irrelevant, 4=perfect)\n",
        "\n",
        "# Load queries\n",
        "queries_file = acord_data['train']  # Example access\n",
        "print(f\"\\nğŸ“‹ Sample Query:\")\n",
        "print(json.dumps(queries_file, indent=2)[:500])\n",
        "\n",
        "# Show statistics\n",
        "print(f\"\\nğŸ“Š ACORD Statistics:\")\n",
        "print(f\"   Queries: 114 expert-written\")\n",
        "print(f\"   Clauses: 3000+ from 450 contracts\")\n",
        "print(f\"   Query-Clause Pairs: 126,000+\")\n",
        "print(f\"   Ratings: 1-5 stars (by lawyers)\")\n",
        "print(f\"   Categories: 9 complex clause types\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVjzzUtorGqp",
        "outputId": "4555c408-e873-4bb3-8a47-ff5797962a91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ”„ Converting to instruction format...\n",
            "================================================================================\n",
            "âœ… Converted 1496 samples for train\n",
            "âœ… Converted 1726 samples for test\n",
            "\n",
            "ğŸ“ Example Training Sample:\n",
            "   Instruction: Extract the exact Limitation of Liability clause that matches this requirement\n",
            "   Input (first 200 chars): Requirement: Cap on liability without carveouts\n",
            "\n",
            "Contract Text: 15. LIMITATIONS OF LIABILITY\n",
            "MORPHO agrees that XIMAGE's total liability to MORPHO for any damages suffered in connection with, or arisi...\n",
            "   Output (first 200 chars): 15. LIMITATIONS OF LIABILITY\n",
            "MORPHO agrees that XIMAGE's total liability to MORPHO for any damages suffered in connection with, or arising out of, this Agreement or MORPHO's use of any documentation, ...\n",
            "   Clause Type: Limitation of Liability\n",
            "   Relevance: 3/4\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from collections import defaultdict\n",
        "\n",
        "print(\"ğŸ”„ Converting ACORD to instruction format...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ACORD format conversion strategy:\n",
        "# - Each query-clause pair with rating >= 3 (good/excellent) becomes a training sample\n",
        "# - Query text â†’ instruction\n",
        "# - Clause text â†’ both input and output (teach model to extract/copy)\n",
        "# - Include relevance score for future weighted training\n",
        "\n",
        "def convert_acord_to_instruction_format(acord_dataset, min_relevance=3):\n",
        "    \"\"\"\n",
        "    Convert ACORD BEIR format to instruction format for fine-tuning.\n",
        "\n",
        "    Args:\n",
        "        acord_dataset: ACORD dataset from HuggingFace\n",
        "        min_relevance: Minimum relevance score (0-4). Default 3 = 4-5 star clauses.\n",
        "\n",
        "    Returns:\n",
        "        List of training samples in instruction format\n",
        "    \"\"\"\n",
        "\n",
        "    training_data = []\n",
        "\n",
        "    # Access ACORD components\n",
        "    # Note: Actual structure depends on how ACORD is formatted\n",
        "    # You may need to adjust based on actual data structure\n",
        "\n",
        "    for split_name in ['train', 'validation']:\n",
        "        if split_name not in acord_dataset:\n",
        "            continue\n",
        "\n",
        "        split_data = acord_dataset[split_name]\n",
        "\n",
        "        for item in split_data:\n",
        "            # Extract query and clause\n",
        "            # Adjust field names based on actual ACORD structure\n",
        "            query_text = item.get('query', item.get('question', ''))\n",
        "            clause_text = item.get('clause', item.get('text', item.get('context', '')))\n",
        "            relevance = item.get('score', item.get('relevance', 0))\n",
        "            category = item.get('category', item.get('clause_type', 'General'))\n",
        "\n",
        "            # Only include relevant clauses (3-4 stars = 4-5 star rating)\n",
        "            if relevance >= min_relevance:\n",
        "                training_data.append({\n",
        "                    'instruction': f'Extract the exact {category} clause that matches this requirement',\n",
        "                    'input': f\"Requirement: {query_text}\\n\\nContract Text: {clause_text}\",\n",
        "                    'output': clause_text,\n",
        "                    'clause_type': category,\n",
        "                    'relevance_score': relevance,\n",
        "                    'metadata': {\n",
        "                        'query': query_text,\n",
        "                        'split': split_name\n",
        "                    }\n",
        "                })\n",
        "\n",
        "    return training_data\n",
        "\n",
        "# Convert data\n",
        "train_data = convert_acord_to_instruction_format(acord_data, min_relevance=3)\n",
        "\n",
        "print(f\"âœ… Conversion complete!\")\n",
        "print(f\"   Total samples: {len(train_data)}\")\n",
        "print(f\"   Min relevance: 3 stars (good/excellent clauses)\")\n",
        "\n",
        "# Show example\n",
        "print(f\"\\nğŸ“ Example Training Sample:\")\n",
        "print(f\"   Instruction: {train_data['instruction']}\")\n",
        "print(f\"   Input (first 200 chars): {train_data['input'][:200]}...\")\n",
        "print(f\"   Output (first 200 chars): {train_data['output'][:200]}...\")\n",
        "print(f\"   Clause Type: {train_data['clause_type']}\")\n",
        "print(f\"   Relevance: {train_data['relevance_score']}/4 stars\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqSoVmPcrRA3",
        "outputId": "c6713efb-57a0-46e2-8e83-695fa0b0f4b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“ˆ Data Augmentation...\n",
            "âš ï¸  Training set has 1496 samples - applying 3x augmentation\n",
            "âœ… Augmented to 4488 samples\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "print(\"ğŸ”„ Applying data augmentation...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def augment_training_data(data, augmentation_factor=2):\n",
        "    \"\"\"\n",
        "    Augment training data by creating variations.\n",
        "    Useful if ACORD dataset is too small (114 queries).\n",
        "    \"\"\"\n",
        "\n",
        "    augmented = []\n",
        "\n",
        "    # Instruction variations\n",
        "    instruction_templates = [\n",
        "        'Extract the exact {clause_type} clause that matches this requirement',\n",
        "        'Copy the {clause_type} clause from this contract that satisfies the following',\n",
        "        'Find and extract the {clause_type} clause based on this description',\n",
        "        'Locate the {clause_type} clause in the contract matching',\n",
        "        'Identify and extract the relevant {clause_type} clause for',\n",
        "    ]\n",
        "\n",
        "    for sample in data:\n",
        "        # Add original\n",
        "        augmented.append(sample)\n",
        "\n",
        "        # Create variations with different instruction templates\n",
        "        for i in range(augmentation_factor - 1):\n",
        "            template = random.choice(instruction_templates)\n",
        "            augmented_sample = sample.copy()\n",
        "            augmented_sample['instruction'] = template.format(\n",
        "                clause_type=sample['clause_type']\n",
        "            )\n",
        "            augmented.append(augmented_sample)\n",
        "\n",
        "    return augmented\n",
        "\n",
        "# Augment if needed\n",
        "if len(train_data) < 1000:\n",
        "    print(f\"âš ï¸ Dataset has {len(train_data)} samples - applying 3x augmentation\")\n",
        "    train_data = augment_training_data(train_data, augmentation_factor=3)\n",
        "    print(f\"âœ… Augmented to {len(train_data)} samples\")\n",
        "else:\n",
        "    print(f\"âœ… Dataset has {len(train_data)} samples - augmentation not needed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "ov-h4X9LrlPk",
        "outputId": "22c45b20-5d25-4c7e-8dcc-c323db996142"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Š Creating data splits...\n",
            "================================================================================\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'train_data' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3266322180.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Shuffle data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Split: 70% train, 15% val, 15% test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"ğŸ“Š Creating data splits...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Shuffle data\n",
        "random.seed(42)\n",
        "random.shuffle(train_data)\n",
        "\n",
        "# Split: 70% train, 15% val, 15% test\n",
        "train_split, temp = train_test_split(train_data, test_size=0.3, random_state=42)\n",
        "val_split, test_split = train_test_split(temp, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"âœ… Data splits created:\")\n",
        "print(f\"   Train: {len(train_split)} samples (70%)\")\n",
        "print(f\"   Validation: {len(val_split)} samples (15%)\")\n",
        "print(f\"   Test: {len(test_split)} samples (15%)\")\n",
        "\n",
        "# Verify clause type distribution\n",
        "from collections import Counter\n",
        "\n",
        "train_types = Counter(s['clause_type'] for s in train_split)\n",
        "print(f\"\\nğŸ“‹ Clause type distribution in training set:\")\n",
        "for clause_type, count in train_types.most_common():\n",
        "    print(f\"   {clause_type}: {count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCBlxiJhroiu",
        "outputId": "ab211902-4425-4e7a-e026-c874d5993365"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample query structure:\n",
            "{\n",
            "  \"_id\": \"New York Governing Law\",\n",
            "  \"text\": \"New York Governing Law\",\n",
            "  \"metadata\": {\n",
            "    \"category\": \"Governing Law\",\n",
            "    \"parent_query_id\": \"\",\n",
            "    \"type\": \"cuad1\",\n",
            "    \"split\": \"train\"\n",
            "  }\n",
            "}\n",
            "\n",
            "Query metadata keys:\n",
            "dict_keys(['category', 'parent_query_id', 'type', 'split'])\n"
          ]
        }
      ],
      "source": [
        "# Check what's actually in the queries\n",
        "print(\"Sample query structure:\")\n",
        "print(json.dumps(list(queries_dict.values())[0], indent=2))\n",
        "print(\"\\nQuery metadata keys:\")\n",
        "print(list(queries_dict.values())[0].get('metadata', {}).keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gv1MCPa1r2eF",
        "outputId": "ae05ab39-29c1-4e59-b6f8-540e6a20ba33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ’¾ Saving converted data...\n",
            "================================================================================\n",
            "âœ… Saved train.json - 4488 samples (13.19 MB)\n",
            "âœ… Saved test.json - 1726 samples (5.12 MB)\n",
            "\n",
            "âœ… All files saved to: /kaggle/working/acord_data\n",
            "   Files: train.json, test.json, metadata.json\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 6: Save Converted Data\n",
        "# ============================================================================\n",
        "\n",
        "print(f\"\\nğŸ’¾ Saving converted data...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "output_dir = \"/kaggle/working/acord_data\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Save each split\n",
        "for split, data in training_data.items():\n",
        "    output_path = f\"{output_dir}/{split}.json\"\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"âœ… Saved {split}.json - {len(data)} samples ({os.path.getsize(output_path)/1024/1024:.2f} MB)\")\n",
        "\n",
        "# Save metadata\n",
        "metadata = {\n",
        "    'dataset': 'ACORD (Atticus Clause Retrieval Dataset)',\n",
        "    'source': 'The Atticus Project (Google Drive)',\n",
        "    'conversion_date': '2025-10-30',\n",
        "    'min_relevance_score': 1,\n",
        "    'total_queries': len(queries_dict),\n",
        "    'total_clauses': len(corpus_dict),\n",
        "    'splits': {split: len(data) for split, data in training_data.items()},\n",
        "    'augmentation': {\n",
        "        'train': 3 if len(training_data.get('train', [])) < 5000 else 1,\n",
        "        'validation': 1,\n",
        "        'test': 1\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(f\"{output_dir}/metadata.json\", 'w') as f:\n",
        "    json.dump(metadata, f, indent=2)\n",
        "\n",
        "print(f\"\\nâœ… All files saved to: {output_dir}\")\n",
        "print(f\"   Files: {', '.join([f'{s}.json' for s in training_data.keys()])}, metadata.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWiZfknpsqP3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
